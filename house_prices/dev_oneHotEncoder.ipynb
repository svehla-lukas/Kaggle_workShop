{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset with OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def prepare_features(x_data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    X_train = vstupn√≠ featury (normalizovan√©, zak√≥dovan√©, p≈ôipraven√©)\n",
    "    y_train = c√≠lov√° hodnota (ve tv√©m p≈ô√≠padƒõ MSSubClass)\n",
    "    transformer = pipeline pro pou≈æit√≠ na testovac√≠ch datech\n",
    "    \"\"\"\n",
    "    X = x_data_frame.copy()\n",
    "\n",
    "    # # 1. Rozdƒõlen√≠ c√≠lov√© promƒõnn√© a vstup≈Ø\n",
    "    # y = df[target_column]\n",
    "\n",
    "    # 2. Rozdƒõlen√≠ sloupc≈Ø\n",
    "    numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "    # 3. Tvorba transformac√≠\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numerical_cols),\n",
    "            (\n",
    "                \"cat\",\n",
    "                OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "                categorical_cols,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 4. Pipeline (m≈Ø≈æe≈° pou≈æ√≠t i s modely jako XGBoost, NN atd.)\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor)])\n",
    "\n",
    "    # 5. Fit + transform vstupn√≠ data\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "    # 6. Z√≠sk√°n√≠ n√°zv≈Ø nov√Ωch sloupc≈Ø (voliteln√©)\n",
    "    new_columns = []\n",
    "\n",
    "    if numerical_cols:\n",
    "        new_columns += numerical_cols\n",
    "\n",
    "    if categorical_cols:\n",
    "        encoder = pipeline.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "        new_columns += encoder.get_feature_names_out(categorical_cols).tolist()\n",
    "\n",
    "    X_transformed_df = pd.DataFrame(X_transformed, columns=new_columns, index=X.index)\n",
    "\n",
    "    return X_transformed_df, pipeline  # X, y, transformer pro testovac√≠ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from data_set/train.csv\n",
      "dimension train data: (1460, 81)\n",
      "dimension train data: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "path_train_data = \"data_set/train.csv\"\n",
    "\n",
    "# origin_data_df = utils.load_csv_data(path_train_data)\n",
    "origin_data_df = utils.load_csv_data(path_train_data)\n",
    "# Debugging: Check the type of train_data\n",
    "\n",
    "# Print the loaded data\n",
    "if isinstance(origin_data_df, pd.DataFrame):\n",
    "    print(f\"dimension train data: {origin_data_df.shape}\")\n",
    "    print(f\"dimension train data: {type(origin_data_df)}\")\n",
    "else:\n",
    "    print(\"train_data is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train target data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train data\n",
    "train_target_df = origin_data_df[\"SalePrice\"]\n",
    "\n",
    "# Drop the Id and sales price column\n",
    "train_data_df = origin_data_df.drop(columns=[\"Id\"]).drop(columns=[\"SalePrice\"])\n",
    "train_data_df = utils.auto_clean_columns(train_data_df)\n",
    "\n",
    "\n",
    "print(f\"train_data_df dataType:{type(train_data_df)}\")\n",
    "print(f\"train_target_df dataType:{type(train_target_df)}\")\n",
    "print(f\"train_data_df shape: {train_data_df.shape}\")\n",
    "print(f\"train_target_df shape: {train_target_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X_train = vstupn√≠ featury (normalizovan√©, zak√≥dovan√©, p≈ôipraven√©)\n",
    "- y_train = c√≠lov√° hodnota (ve tv√©m p≈ô√≠padƒõ MSSubClass)\n",
    "- transformer = pipeline pro pou≈æit√≠ na testovac√≠ch datech\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_OneHotEnc, transformer = prepare_features(train_data_df)\n",
    "# print(transformer)\n",
    "print(f\"x_train_OneHotEnc shape: {train_data_OneHotEnc.shape}\")\n",
    "print(type(train_data_OneHotEnc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(train_data_df.columns))\n",
    "print(\"-------------\")\n",
    "print(list(train_data_OneHotEnc.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data with transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data = \"data_set/test.csv\"\n",
    "\n",
    "test_data = utils.load_csv_data(path_test_data)\n",
    "# Debugging: Check the type of test_data\n",
    "\n",
    "# Print the loaded data\n",
    "if isinstance(test_data, pd.DataFrame):\n",
    "    print(f\"dimension train data: {test_data.shape}\")\n",
    "else:\n",
    "    print(\"test_data is not a DataFrame\")\n",
    "print(type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=[\"Id\"])\n",
    "print(test_data.shape)\n",
    "test_data = utils.auto_clean_columns(test_data)\n",
    "# test_data = test_data.replace(\"NA\", np.nan)\n",
    "print(type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target = transformer.transform(test_data)\n",
    "print(type(x_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare test targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_target_data = \"data_set/sample_submission.csv\"\n",
    "\n",
    "target_data = utils.load_csv_data(path_target_data)\n",
    "# Debugging: Check the type of test_data\n",
    "\n",
    "# Print the loaded data\n",
    "if isinstance(target_data, pd.DataFrame):\n",
    "    print(f\"dimension train data: {target_data.shape}\")\n",
    "else:\n",
    "    print(\"test_data is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = target_data.drop(columns=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_target.shape)\n",
    "print(y_target.shape)\n",
    "print(type(x_target))\n",
    "print(type(y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Se jm√©ny sloupc≈Ø z transformace\n",
    "# num_cols = transformer.named_steps[\"preprocessor\"].transformers_[0][2]\n",
    "# cat_encoder = transformer.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "# cat_cols = cat_encoder.get_feature_names_out(\n",
    "#     transformer.named_steps[\"preprocessor\"].transformers_[1][2]\n",
    "# )\n",
    "\n",
    "# all_cols = list(num_cols) + list(cat_cols)\n",
    "\n",
    "# # P≈ôevod na DataFrame\n",
    "# import pandas as pd\n",
    "\n",
    "# x_target = pd.DataFrame(x_target, columns=all_cols, index=test_data.index)\n",
    "# print(type(y_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "def build_model(input_parameters):\n",
    "    input_shape = (input_parameters,)  # 304 parameters of house\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(838, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(1600, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))  # regresn√≠ v√Ωstup\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "k = 1\n",
    "num_val_samples = len(x_train) // k\n",
    "num_epochs = 10\n",
    "all_scores = []\n",
    "all_histories = []\n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"processing fold # {i}\")\n",
    "    val_data = x_train[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    partial_train_data = pd.concat(\n",
    "        [x_train[: i * num_val_samples], x_train[(i + 1) * num_val_samples :]]\n",
    "    )\n",
    "    partial_train_targets = pd.concat(\n",
    "        [y_train[: i * num_val_samples], y_train[(i + 1) * num_val_samples :]]\n",
    "    )\n",
    "\n",
    "    model = build_model(x_train.shape[1])\n",
    "    print(\"- üß† Spou≈°t√≠m tr√©nov√°n√≠...\")\n",
    "    history = model.fit(\n",
    "        partial_train_data,\n",
    "        partial_train_targets,\n",
    "        validation_data=(val_data, val_targets),\n",
    "        epochs=num_epochs,\n",
    "        batch_size=64,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    print(f\"- ‚úÖ Fold {i + 1} finished: val_mae = {val_mae:.2f}\")\n",
    "    _ = utils.plot_history(history.history, metric=\"mae\")\n",
    "    all_scores.append(val_mae)\n",
    "    all_histories.append(history)\n",
    "\n",
    "print(all_scores)\n",
    "print(f\"üïí Celkov√Ω ƒças tr√©nov√°n√≠: {time.time() - start:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on whole data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "origin_data_df_clean = utils.auto_clean_columns(origin_data_df)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    origin_data_df_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# y\n",
    "\n",
    "y_train = utils.to_numpy(train_df[\"SalePrice\"])\n",
    "y_val = utils.to_numpy(val_df[\"SalePrice\"])\n",
    "\n",
    "y_train_log = np.log1p(y_train)  # log(1 + y)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "\n",
    "# X (bez 'Id' a 'SalePrice')\n",
    "train_data = train_df.drop(columns=[\"Id\", \"SalePrice\"])\n",
    "val_data = val_df.drop(columns=[\"Id\", \"SalePrice\"])\n",
    "\n",
    "# Feature preparation\n",
    "x_train, transformer = prepare_features(train_data)\n",
    "x_val = transformer.transform(val_data)\n",
    "\n",
    "x_train = utils.to_numpy(x_train)\n",
    "x_val = utils.to_numpy(x_val)\n",
    "\n",
    "variables = {\n",
    "    \"x_train\": x_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"x_val\": x_val,\n",
    "    \"y_val\": y_val,\n",
    "}\n",
    "\n",
    "for name, var in variables.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  type: {type(var)}\")\n",
    "    print(f\"  shape: {var.shape}\")\n",
    "\n",
    "print(np.isnan(x_val).sum())  # mus√≠ b√Ωt 0\n",
    "print(np.isnan(x_train).sum())  # mus√≠ b√Ωt 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "def build_model(input_parameters):\n",
    "    input_shape = (input_parameters,)  # 304 parameters of house\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    # model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))  # regresn√≠ v√Ωstup\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model = build_model(x_train.shape[1])\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train_log,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val_log),\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "\n",
    "val_mse, val_mae = model.evaluate(x_val, y_val_log, verbose=0)\n",
    "print(f\"- ‚úÖ finished: val_mae = {val_mae:.2f}\")\n",
    "_ = utils.plot_history(history.history, metric=\"mae\")\n",
    "# _ = utils.plot_history(history.history, metric=\"loss\")\n",
    "\n",
    "print(val_mae)\n",
    "print(np.expm1(val_mae))\n",
    "print(f\"üïí Celkov√Ω ƒças tr√©nov√°n√≠: {time.time() - start:.2f} s\")\n",
    "# Predikce ve val log-space\n",
    "y_val_pred_log = model.predict(x_val)\n",
    "y_val_pred = np.expm1(y_val_pred_log)\n",
    "y_val_true = y_val\n",
    "\n",
    "# MAE v p≈Øvodn√≠ch jednotk√°ch\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_usd = mean_absolute_error(y_val_true, y_val_pred)\n",
    "print(f\"üéØ Skuteƒçn√Ω MAE v USD: {mae_usd:,.0f} USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"house_prices_oneSotEncoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history[\"loss\"][-5:])\n",
    "print(history.history[\"val_loss\"][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_debug(index: int):\n",
    "    \"\"\"\n",
    "    Debug predikce na tr√©novac√≠ch datech podle p≈Øvodn√≠ch vstupn√≠ch hodnot.\n",
    "    \"\"\"\n",
    "    # 1. Z√≠sk√°n√≠ p≈Øvodn√≠ch vstupn√≠ch dat (ne≈°k√°lovan√Ωch, nesparsovan√Ωch)\n",
    "    raw_input = train_data.iloc[[index]]  # DataFrame s jedn√≠m ≈ô√°dkem\n",
    "    true_price = y_train[index]\n",
    "\n",
    "    # 2. Transformace vstupu pomoc√≠ pipeline (StandardScaler + OneHotEncoder)\n",
    "    x_input = transformer.transform(raw_input)\n",
    "\n",
    "    # 3. Predikce\n",
    "    predicted_price = model.predict(x_input, verbose=0)[0][0]\n",
    "    predicted_price = np.expm1(predicted_price)\n",
    "    # 4. V√Ωpis\n",
    "    print(f\"üîç Index: {index}\")\n",
    "    print(f\"üéØ Skuteƒçn√° cena: {true_price:,.0f} USD\")\n",
    "    print(f\"ü§ñ Predikovan√° cena: {predicted_price:,.0f} USD\")\n",
    "    print(f\"üìâ Rozd√≠l: {true_price - predicted_price:,.0f} USD\")\n",
    "\n",
    "    # Volitelnƒõ ‚Äì v√Ωpis vstupn√≠ch hodnot\n",
    "    # print(\"\\nüßæ Vstupn√≠ featury:\")\n",
    "    # display(raw_input.T)  # pokud jsi v notebooku\n",
    "\n",
    "\n",
    "for i in [0, 20, 40, 60, 70, 80]:\n",
    "    print(predict_debug(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Min: {y_train.min():,.0f} USD\")\n",
    "print(f\"Max: {y_train.max():,.0f} USD\")\n",
    "print(f\"Mean: {y_train.mean():,.0f} USD\")\n",
    "\n",
    "max_diff = 0\n",
    "min_diff = 0\n",
    "count = 10  # nebo x_train.shape[0] podle pot≈ôeby\n",
    "\n",
    "for i in range(count):\n",
    "    features = x_train[i]\n",
    "    prediction = model.predict(features, verbose=0)[0][0]\n",
    "    true_value = y_train[i]\n",
    "\n",
    "    diff = int(true_value - prediction)\n",
    "    pred_int = int(prediction)\n",
    "    true_int = int(true_value)\n",
    "\n",
    "    if diff > max_diff:\n",
    "        max_diff = diff\n",
    "    elif diff < min_diff:\n",
    "        min_diff = diff\n",
    "\n",
    "    print(\n",
    "        f\"diff = {format(diff, ',')} USD | \"\n",
    "        f\"prediction = {format(pred_int, ',')} USD | \"\n",
    "        f\"target = {format(true_int, ',')} USD\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"\\nmin_diff = {format(min_diff, ',')} USD |\"\n",
    "    f\"\\nmax_diff = {format(max_diff, ',')} USD |\"\n",
    ")\n",
    "\n",
    "# V√Ωpoƒçet predikc√≠ a graf\n",
    "preds = [\n",
    "    model.predict(x_train[i].reshape(1, -1), verbose=0)[0][0] for i in range(count)\n",
    "]\n",
    "trues = y_train[:count]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trues, marker=\"o\", label=\"Skuteƒçn√© ceny\")\n",
    "plt.plot(preds, marker=\"o\", label=\"Predikovan√© ceny\")\n",
    "plt.title(\"Porovn√°n√≠ predikce vs. skuteƒçnost (tr√©novac√≠ data)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Cena (v USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(x_train, axis=0))  # smƒõrodatn√° odchylka po sloupc√≠ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(x_train, axis=0))\n",
    "print(np.max(x_train, axis=0))\n",
    "print(np.mean(x_train, axis=0))\n",
    "print(np.std(x_train, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ruin model on target data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x_train_df))\n",
    "print(type(y_train_df))\n",
    "print(\"--- convert ---\")\n",
    "x_train = utils.to_numpy(x_train_df)\n",
    "y_train = utils.to_numpy(y_train_df)\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Min: {y_target.min():,.0f} USD\")\n",
    "print(f\"Max: {y_target.max():,.0f} USD\")\n",
    "print(f\"Mean: {y_target.mean():,.0f} USD\")\n",
    "\n",
    "max_diff = 0\n",
    "min_diff = 0\n",
    "count = 10  # nebo x_target.shape[0] podle pot≈ôeby\n",
    "\n",
    "for i in range(count):\n",
    "    features = x_target[i].reshape(1, -1)  # bez .iloc\n",
    "    prediction = model.predict(features, verbose=0)[0][0]\n",
    "    target_value = y_target[i]\n",
    "\n",
    "    diff = int(target_value - prediction)\n",
    "    pred_int = int(prediction)\n",
    "    target_int = int(target_value)\n",
    "\n",
    "    if diff > max_diff:\n",
    "        max_diff = diff\n",
    "    elif diff < min_diff:\n",
    "        min_diff = diff\n",
    "\n",
    "    print(\n",
    "        f\"diff = {format(diff, ',')} USD | \"\n",
    "        f\"prediction = {format(pred_int, ',')} USD | \"\n",
    "        f\"target = {format(target_int, ',')} USD\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"\\nmin_diff = {format(min_diff, ',')} USD |\"\n",
    "    f\"\\nmax_diff = {format(max_diff, ',')} USD |\"\n",
    ")\n",
    "\n",
    "# V√Ωpoƒçet predikc√≠ a vykreslen√≠ grafu\n",
    "preds = [\n",
    "    model.predict(x_target[i].reshape(1, -1), verbose=0)[0][0] for i in range(count)\n",
    "]\n",
    "trues = y_target[:count]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trues, marker=\"o\", label=\"Skuteƒçn√© ceny\")\n",
    "plt.plot(preds, marker=\"o\", label=\"Predikovan√© ceny\")\n",
    "plt.title(\"Porovn√°n√≠ predikce vs. skuteƒçnost\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Cena (v USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üìä V√Ωsledky cross-validace:\")\n",
    "for i, score in enumerate(all_scores):\n",
    "    print(f\"Fold {i + 1}: MAE = {score:.2f}\")\n",
    "\n",
    "average = np.mean(all_scores)\n",
    "print(\"-\" * 50)\n",
    "print(f\"üìà Pr≈Ømƒõrn√° MAE p≈ôes {k} fold≈Ø: {average:.2f}\")\n",
    "\n",
    "epoch_maes = [\n",
    "    [history.history[\"mae\"][epoch] for history in all_histories]\n",
    "    for epoch in range(num_epochs)\n",
    "]\n",
    "average_mae_history = [np.mean(epoch) for epoch in epoch_maes]\n",
    "std_mae_history = [np.std(epoch) for epoch in epoch_maes]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    range(1, num_epochs + 1), average_mae_history, marker=\"o\", label=\"Pr≈Ømƒõrn√° MAE\"\n",
    ")\n",
    "plt.fill_between(\n",
    "    range(1, num_epochs + 1),\n",
    "    np.array(average_mae_history) - np.array(std_mae_history),\n",
    "    np.array(average_mae_history) + np.array(std_mae_history),\n",
    "    alpha=0.2,\n",
    "    label=\"¬± 1 std\",\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"üìà Pr≈Ømƒõrn√° MAE s rozptylem (v≈°echny foldy)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    predictions = model.predict(x_target.iloc[[i]], verbose=0)\n",
    "    target_value = y_target.iloc[i]\n",
    "\n",
    "    diff = int(target_value - predictions[0][0])\n",
    "    pred = int(predictions[0][0])\n",
    "    target = int(target_value)\n",
    "\n",
    "    print(\n",
    "        f\"diff = {format(diff, ',').replace(',', ' ')} USD | \"\n",
    "        f\"prediction = {format(pred, ',').replace(',', ' ')} USD | \"\n",
    "        f\"target = {format(target, ',').replace(',', ' ')} USD\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
